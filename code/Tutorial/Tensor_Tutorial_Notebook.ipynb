{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From:\n",
    "https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html\n",
    "\n",
    "\n",
    "Environment was created with:\n",
    "conda create --name  Nystromformer python=3.7\n",
    "conda install -n Nystromformer pip\n",
    "conda activate Nystromformer\n",
    "\n",
    "!pip install torch==1.7.1\n",
    "!pip install torchvision==0.8.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1, 2],[3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numpy\n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from another tensor\n",
    "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shape\n",
    "shape = (2,3)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor attributes\n",
    "\n",
    "tensor = torch.rand(3,4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We move our tensor to the GPU if available\n",
    "if torch.cuda.is_available():\n",
    "  tensor = tensor.to('cuda')\n",
    "\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This computes the element-wise product\n",
    "print(f\"tensor.mul(tensor) \\n {tensor.mul(tensor)} \\n\")\n",
    "# Alternative syntax:\n",
    "print(f\"tensor * tensor \\n {tensor * tensor}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inplace operators have a suffix _\n",
    "print(tensor, \"\\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Gentle Introduction to torch.autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda remove pytorch torchvision -y\n",
    "# !pip uninstall torch -y\n",
    "# !pip uninstall torch -y  # yes twice\n",
    "# !pip3 uninstall -y torch torchvision\n",
    "# !pip3 uninstall -y torch torchvision\n",
    "# !pip uninstall -y torch torchvision\n",
    "# !pip uninstall -y torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==1.7.0\n",
      "  Using cached https://files.pythonhosted.org/packages/d9/74/d52c014fbfb50aefc084d2bf5ffaa0a8456f69c586782b59f93ef45e2da9/torch-1.7.0-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: typing-extensions in /home/dwane/anaconda3/lib/python3.7/site-packages (from torch==1.7.0) (3.7.4.3)\n",
      "Requirement already satisfied: dataclasses in /home/dwane/anaconda3/lib/python3.7/site-packages (from torch==1.7.0) (0.6)\n",
      "Requirement already satisfied: future in /home/dwane/anaconda3/lib/python3.7/site-packages (from torch==1.7.0) (0.17.1)\n",
      "Requirement already satisfied: numpy in /home/dwane/anaconda3/lib/python3.7/site-packages (from torch==1.7.0) (1.18.3)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Using cached https://files.pythonhosted.org/packages/94/df/969e69a94cff1c8911acb0688117f95e1915becc1e01c73e7960a2c76ec8/torchvision-0.8.2-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/dwane/anaconda3/lib/python3.7/site-packages (from torchvision) (6.2.2)\n",
      "Collecting torch==1.7.1 (from torchvision)\n",
      "  Using cached https://files.pythonhosted.org/packages/90/5d/095ddddc91c8a769a68c791c019c5793f9c4456a688ddd235d6670924ecb/torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: numpy in /home/dwane/anaconda3/lib/python3.7/site-packages (from torchvision) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions in /home/dwane/anaconda3/lib/python3.7/site-packages (from torch==1.7.1->torchvision) (3.7.4.3)\n",
      "Installing collected packages: torch, torchvision\n",
      "  Found existing installation: torch 1.7.0\n",
      "    Uninstalling torch-1.7.0:\n",
      "      Successfully uninstalled torch-1.7.0\n",
      "Successfully installed torch-1.7.1 torchvision-0.8.2\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision==0.8.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /home/dwane/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12943024bdd24f86afb9f467b8acbe53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Letâ€™s take a look at a single training step. For this example, we load a pretrained resnet18 model from torchvision. We create a random data tensor to represent a single image with 3 channels, and height & width of 64, and its corresponding label initialized to some random values.\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "data = torch.rand(1, 3, 64, 64)\n",
    "labels = torch.rand(1, 1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.6626e-01, 8.2316e-02, 5.9400e-01, 7.5936e-01, 8.6737e-01, 8.9686e-01,\n",
       "         5.9160e-01, 1.6544e-01, 7.2463e-01, 6.2511e-01, 5.4458e-01, 1.8370e-01,\n",
       "         3.8388e-01, 5.2989e-01, 1.7357e-01, 2.3498e-01, 3.0136e-01, 5.1489e-01,\n",
       "         1.6585e-01, 1.8782e-01, 7.9534e-01, 8.7524e-01, 1.8033e-01, 5.2435e-01,\n",
       "         3.6063e-01, 5.4711e-01, 6.1993e-02, 2.5763e-01, 1.2420e-01, 1.2999e-02,\n",
       "         5.6458e-01, 5.3822e-01, 2.3454e-01, 3.9489e-01, 2.0807e-03, 7.7471e-01,\n",
       "         4.2021e-01, 2.1290e-01, 1.1530e-01, 6.4206e-01, 7.7055e-02, 7.2619e-01,\n",
       "         3.5804e-01, 2.0777e-01, 7.1456e-02, 3.3471e-01, 7.9956e-02, 2.1458e-02,\n",
       "         4.5298e-01, 9.4458e-01, 8.1020e-01, 3.3597e-01, 2.6055e-01, 8.4183e-02,\n",
       "         1.1382e-01, 3.1146e-02, 2.0742e-01, 6.4672e-01, 5.7201e-01, 5.1224e-01,\n",
       "         8.7523e-01, 5.9597e-01, 7.0507e-02, 3.3938e-01, 3.3311e-01, 4.6237e-01,\n",
       "         3.3460e-01, 8.3869e-01, 2.9677e-01, 6.8951e-01, 8.8685e-01, 2.6774e-02,\n",
       "         4.8318e-01, 9.7901e-01, 3.9274e-01, 4.3770e-01, 5.0409e-01, 2.4619e-01,\n",
       "         3.3677e-01, 1.6377e-01, 5.5227e-01, 8.1892e-02, 4.2853e-01, 1.3159e-01,\n",
       "         8.6478e-01, 7.2213e-01, 3.1682e-01, 2.7636e-01, 8.6540e-01, 1.3052e-01,\n",
       "         1.2802e-01, 9.1199e-01, 6.1528e-02, 9.8891e-01, 1.1501e-01, 9.3921e-01,\n",
       "         3.9839e-01, 4.9202e-01, 7.4719e-01, 2.2972e-01, 8.2779e-01, 6.3439e-01,\n",
       "         5.8614e-01, 3.1967e-01, 5.4721e-01, 9.6226e-01, 1.3776e-01, 4.5599e-01,\n",
       "         3.1974e-01, 9.0789e-01, 4.1511e-01, 7.4096e-01, 3.8813e-01, 4.9462e-01,\n",
       "         5.8224e-01, 2.1599e-01, 7.6721e-01, 6.7004e-01, 1.9094e-01, 5.7778e-01,\n",
       "         1.5379e-01, 2.3388e-01, 6.8841e-02, 8.5179e-01, 9.2303e-01, 1.9488e-01,\n",
       "         5.8625e-01, 2.0691e-01, 4.5294e-01, 8.0241e-01, 2.5374e-01, 1.5877e-01,\n",
       "         1.8127e-01, 1.1885e-01, 2.5330e-01, 9.0489e-01, 5.6740e-01, 1.8940e-01,\n",
       "         3.9240e-01, 1.0844e-01, 7.7407e-01, 8.2407e-01, 1.5093e-01, 5.7304e-01,\n",
       "         8.4610e-02, 2.8461e-01, 2.2140e-01, 6.2479e-01, 4.9093e-01, 6.8605e-01,\n",
       "         5.7774e-01, 1.9608e-01, 2.6448e-02, 9.4950e-01, 7.2220e-01, 6.5620e-01,\n",
       "         5.5054e-02, 2.8924e-01, 3.5824e-01, 9.3925e-02, 4.2761e-01, 5.8977e-01,\n",
       "         1.2777e-01, 6.5859e-01, 7.9749e-02, 6.9151e-01, 9.6902e-02, 2.8570e-01,\n",
       "         3.0563e-01, 9.3851e-01, 5.3315e-01, 5.4804e-01, 1.7158e-02, 8.6190e-01,\n",
       "         2.8267e-01, 6.6259e-01, 5.6865e-01, 1.7710e-01, 3.0329e-01, 2.5056e-01,\n",
       "         3.2091e-01, 3.2030e-02, 9.6802e-01, 3.0765e-01, 1.8700e-01, 2.0947e-01,\n",
       "         1.0483e-02, 2.9092e-01, 2.3724e-01, 6.2968e-01, 1.7359e-01, 4.5161e-03,\n",
       "         7.3715e-01, 2.7655e-01, 1.0088e-01, 6.0815e-01, 6.0466e-01, 4.1970e-01,\n",
       "         6.2270e-01, 9.0410e-01, 4.6649e-01, 5.7462e-02, 9.9785e-01, 7.1541e-01,\n",
       "         6.5606e-01, 1.1660e-01, 7.9391e-01, 9.2749e-01, 6.8314e-01, 9.1080e-01,\n",
       "         6.9975e-01, 1.3193e-02, 9.5795e-02, 8.3010e-01, 4.6320e-01, 5.9163e-01,\n",
       "         9.5659e-02, 1.3476e-01, 7.3032e-01, 1.3082e-01, 8.1227e-01, 7.0985e-02,\n",
       "         2.9277e-01, 9.2020e-01, 9.5734e-01, 6.4179e-01, 1.8220e-01, 5.4891e-01,\n",
       "         9.4931e-01, 7.6067e-01, 4.7231e-01, 8.4078e-01, 5.2797e-01, 1.7778e-01,\n",
       "         7.6712e-01, 9.7628e-01, 7.0654e-01, 7.8881e-01, 9.7202e-02, 5.5788e-01,\n",
       "         8.2227e-01, 1.5479e-01, 1.0007e-01, 3.8825e-01, 8.0083e-01, 8.7368e-01,\n",
       "         5.4595e-03, 3.1559e-01, 2.1295e-01, 9.2555e-01, 4.6528e-01, 5.5702e-01,\n",
       "         5.0298e-01, 3.2864e-01, 8.5618e-01, 1.6550e-01, 3.9841e-01, 9.5278e-02,\n",
       "         3.1124e-01, 6.0585e-02, 1.1401e-01, 1.4626e-01, 2.3303e-01, 9.3011e-01,\n",
       "         9.9889e-01, 5.0180e-01, 9.1959e-01, 4.5827e-01, 2.8701e-01, 1.6679e-01,\n",
       "         1.5945e-01, 9.2358e-01, 6.3392e-01, 7.2598e-01, 7.1116e-01, 5.9571e-01,\n",
       "         2.3721e-02, 4.4755e-01, 6.8421e-01, 6.0648e-02, 4.8509e-01, 1.8512e-01,\n",
       "         9.4990e-02, 4.9329e-01, 2.0846e-01, 1.6075e-01, 1.9735e-01, 4.6488e-01,\n",
       "         9.6597e-01, 8.0557e-01, 1.2213e-04, 6.2719e-01, 5.9990e-01, 9.3735e-01,\n",
       "         4.2754e-01, 6.5496e-01, 3.1397e-01, 4.2961e-01, 2.4156e-01, 1.2001e-01,\n",
       "         9.2084e-02, 5.7497e-01, 9.5246e-01, 6.4459e-01, 2.2337e-01, 7.8748e-01,\n",
       "         2.6683e-02, 1.0661e-01, 7.4878e-01, 6.7167e-01, 2.3916e-01, 4.6620e-01,\n",
       "         8.6680e-01, 5.2411e-01, 3.5755e-01, 2.1193e-01, 5.6172e-01, 7.8165e-01,\n",
       "         3.7791e-01, 9.0659e-01, 5.2915e-01, 6.6378e-01, 2.2969e-01, 1.0813e-01,\n",
       "         4.0162e-01, 7.9580e-01, 9.7360e-01, 5.6263e-01, 8.2731e-03, 8.2749e-01,\n",
       "         2.9679e-02, 5.9819e-01, 7.6143e-01, 9.7171e-01, 9.8770e-01, 3.9746e-01,\n",
       "         7.0913e-01, 9.2219e-01, 3.0210e-01, 6.4225e-01, 1.8601e-02, 4.8124e-02,\n",
       "         8.6651e-01, 4.0054e-01, 4.5723e-01, 9.0775e-01, 4.2728e-01, 3.5457e-01,\n",
       "         9.4835e-01, 9.2112e-02, 1.8422e-01, 8.3063e-01, 8.1297e-01, 3.8082e-01,\n",
       "         3.5218e-01, 8.6000e-01, 3.1569e-01, 3.6084e-01, 4.0254e-01, 9.9465e-01,\n",
       "         4.9220e-01, 7.0342e-01, 2.6295e-01, 3.8348e-01, 8.5288e-01, 4.4110e-01,\n",
       "         2.3548e-02, 2.0595e-01, 1.2680e-01, 1.2356e-01, 9.8314e-01, 5.1076e-02,\n",
       "         4.6943e-01, 8.3641e-01, 1.5374e-01, 6.5129e-02, 8.7981e-01, 6.8189e-01,\n",
       "         4.4447e-01, 1.3425e-01, 4.4345e-01, 4.2122e-01, 6.3688e-01, 5.5234e-01,\n",
       "         1.4499e-01, 3.0204e-01, 9.8689e-01, 9.9225e-01, 9.3495e-01, 8.3894e-01,\n",
       "         9.0443e-01, 3.2735e-02, 2.7715e-01, 8.1607e-01, 2.7526e-01, 3.8810e-01,\n",
       "         7.7429e-01, 2.9636e-01, 3.1177e-01, 7.2971e-01, 1.1047e-01, 3.7515e-01,\n",
       "         7.5964e-02, 7.2921e-01, 6.5035e-02, 1.5226e-01, 8.4931e-01, 8.3933e-01,\n",
       "         6.9997e-01, 6.4274e-01, 6.1285e-01, 8.4233e-01, 7.8536e-01, 6.8185e-01,\n",
       "         4.6566e-01, 7.5713e-01, 2.5590e-01, 2.4283e-01, 9.2757e-01, 9.4590e-01,\n",
       "         1.3175e-02, 9.2400e-01, 2.3211e-01, 2.0394e-01, 3.9538e-02, 9.5268e-01,\n",
       "         5.9102e-01, 1.7334e-01, 2.5286e-01, 3.7506e-01, 3.5596e-01, 7.3460e-01,\n",
       "         2.7023e-01, 5.2658e-02, 8.4979e-01, 1.6544e-01, 5.3418e-03, 4.3252e-01,\n",
       "         2.6435e-01, 4.6068e-01, 4.4593e-01, 1.6683e-02, 6.6257e-01, 8.4443e-01,\n",
       "         6.1882e-01, 3.5852e-01, 6.5458e-02, 5.9861e-01, 1.8503e-02, 2.0816e-01,\n",
       "         8.6452e-01, 1.6785e-01, 7.9776e-02, 5.3129e-01, 3.0614e-01, 2.6716e-01,\n",
       "         8.9568e-01, 3.8069e-01, 6.5275e-01, 9.2309e-01, 4.9051e-01, 9.1047e-02,\n",
       "         7.9122e-01, 5.2949e-01, 2.2493e-01, 6.8488e-01, 6.9734e-01, 9.8706e-01,\n",
       "         1.9856e-01, 9.2221e-01, 5.9417e-01, 2.5247e-01, 8.9089e-01, 7.5179e-01,\n",
       "         9.3481e-01, 1.9228e-01, 1.0823e-01, 6.8159e-01, 1.4938e-01, 2.2563e-01,\n",
       "         9.7211e-01, 2.3784e-01, 3.5061e-01, 1.6797e-01, 1.9880e-01, 5.7354e-01,\n",
       "         1.4501e-01, 9.9936e-01, 8.9793e-01, 1.7791e-01, 7.2577e-01, 6.3714e-01,\n",
       "         3.7060e-01, 6.6438e-01, 8.6812e-01, 4.6232e-03, 4.5709e-01, 5.5354e-01,\n",
       "         6.0723e-01, 7.3630e-01, 9.0749e-01, 7.3321e-01, 4.6246e-01, 5.1764e-01,\n",
       "         3.5120e-01, 3.5764e-01, 4.2802e-01, 6.8902e-01, 4.4307e-01, 8.6094e-01,\n",
       "         2.5126e-01, 5.5643e-01, 6.7067e-01, 8.3900e-01, 3.9221e-01, 6.6312e-01,\n",
       "         7.0824e-01, 6.2810e-01, 1.4654e-02, 5.8568e-01, 9.9349e-01, 6.8440e-01,\n",
       "         3.8231e-02, 8.8202e-01, 3.0667e-01, 7.7496e-01, 1.4323e-01, 6.4342e-01,\n",
       "         6.9930e-01, 3.8995e-01, 7.6395e-01, 6.7026e-01, 2.5839e-01, 6.7866e-01,\n",
       "         3.5377e-01, 3.7160e-01, 5.5589e-01, 3.9678e-01, 7.7765e-01, 5.8848e-01,\n",
       "         1.0028e-01, 3.9363e-01, 8.0651e-01, 7.6201e-01, 6.3225e-01, 8.8486e-01,\n",
       "         1.8664e-01, 6.8502e-01, 5.5052e-01, 7.2240e-01, 6.4815e-01, 7.7688e-01,\n",
       "         5.5421e-01, 2.6203e-01, 6.9882e-01, 9.6416e-01, 6.5471e-01, 5.0007e-01,\n",
       "         4.1822e-01, 9.8341e-01, 4.6991e-01, 4.5877e-01, 4.6531e-01, 7.8553e-01,\n",
       "         1.8133e-01, 2.2826e-01, 6.9675e-01, 6.5564e-01, 4.7367e-02, 5.9444e-02,\n",
       "         4.5163e-01, 2.2296e-01, 7.6503e-01, 4.2603e-01, 9.5607e-01, 6.4437e-01,\n",
       "         4.2995e-01, 8.9840e-01, 6.6511e-01, 7.6504e-01, 1.1410e-01, 3.7011e-01,\n",
       "         1.0157e-01, 6.6536e-01, 9.0221e-02, 8.0043e-01, 4.3569e-01, 8.7753e-02,\n",
       "         8.8242e-01, 6.2108e-05, 3.0686e-01, 4.8201e-01, 1.5716e-02, 7.3569e-02,\n",
       "         8.0900e-01, 2.4316e-01, 4.3208e-02, 2.8315e-01, 3.4555e-01, 6.9813e-01,\n",
       "         8.4675e-01, 1.9508e-01, 4.9349e-01, 5.3651e-01, 9.9493e-01, 7.7102e-01,\n",
       "         6.3581e-01, 4.1082e-01, 5.0803e-01, 1.7615e-01, 7.0257e-01, 1.1702e-01,\n",
       "         8.9726e-01, 5.0626e-01, 9.4651e-01, 6.2735e-01, 7.3584e-01, 1.2929e-01,\n",
       "         6.7501e-01, 2.8347e-01, 7.6042e-01, 2.2528e-01, 1.2990e-02, 1.7601e-01,\n",
       "         4.6154e-01, 4.6200e-01, 1.2587e-02, 4.2879e-01, 6.8342e-01, 9.8895e-01,\n",
       "         6.1373e-01, 9.4443e-01, 2.2924e-01, 1.1402e-01, 9.8218e-01, 2.1698e-01,\n",
       "         1.4864e-01, 2.1439e-01, 4.9907e-01, 7.7395e-01, 8.8021e-01, 7.0025e-01,\n",
       "         4.9373e-01, 9.1482e-01, 8.1028e-02, 7.8038e-01, 2.7430e-01, 5.6163e-01,\n",
       "         4.7686e-01, 2.1886e-01, 1.8700e-03, 9.2767e-01, 5.4338e-01, 5.9737e-01,\n",
       "         4.0670e-01, 9.1316e-01, 9.8821e-01, 8.8929e-01, 6.3651e-01, 2.1453e-01,\n",
       "         5.8550e-01, 8.7117e-01, 3.2661e-02, 7.9883e-01, 8.2854e-01, 6.5473e-01,\n",
       "         5.3357e-01, 3.4797e-01, 9.7316e-01, 5.6788e-01, 7.4770e-01, 3.3167e-01,\n",
       "         8.6031e-01, 9.6249e-01, 3.5356e-01, 5.6892e-01, 9.4236e-02, 3.9978e-01,\n",
       "         5.4005e-01, 8.4139e-01, 3.2950e-01, 3.6639e-01, 1.0479e-01, 6.5797e-01,\n",
       "         6.9423e-01, 8.3930e-01, 4.0978e-01, 5.3015e-01, 9.0210e-01, 2.8766e-01,\n",
       "         4.9636e-01, 5.7835e-01, 7.0538e-01, 9.0139e-01, 1.8186e-01, 7.0690e-01,\n",
       "         9.8052e-01, 8.6654e-02, 6.2357e-01, 9.5400e-01, 6.7425e-01, 4.1971e-01,\n",
       "         4.4434e-01, 4.2768e-02, 8.9973e-01, 7.1784e-01, 3.2431e-01, 8.3460e-01,\n",
       "         9.4346e-01, 7.7693e-01, 8.3695e-01, 4.1658e-01, 2.9588e-01, 8.0687e-01,\n",
       "         8.1321e-01, 5.8116e-02, 9.8866e-01, 7.3334e-01, 5.2652e-01, 3.1152e-01,\n",
       "         6.0610e-01, 5.1141e-01, 4.1078e-01, 5.9137e-01, 3.1763e-01, 7.5963e-01,\n",
       "         4.3627e-01, 1.3327e-02, 3.8773e-01, 5.4914e-01, 9.9042e-01, 2.1364e-01,\n",
       "         5.8636e-01, 2.5132e-01, 5.6902e-01, 3.2862e-01, 1.9558e-01, 1.5232e-02,\n",
       "         7.2905e-01, 1.6458e-01, 9.3443e-01, 9.3192e-04, 6.4815e-01, 7.8833e-01,\n",
       "         1.8671e-01, 9.0909e-01, 9.4076e-02, 7.8277e-01, 8.5657e-01, 5.0182e-01,\n",
       "         9.7648e-01, 2.0903e-02, 8.1714e-01, 4.5199e-01, 7.4057e-01, 8.0472e-01,\n",
       "         5.9635e-01, 2.1481e-02, 2.7572e-01, 9.5356e-01, 6.1942e-01, 7.4543e-01,\n",
       "         2.4409e-01, 2.7292e-01, 1.8790e-01, 3.6383e-01, 6.5361e-01, 9.6089e-01,\n",
       "         2.3629e-02, 9.5692e-01, 4.7683e-02, 7.8475e-01, 5.3919e-01, 2.4679e-01,\n",
       "         2.8609e-01, 1.3180e-01, 7.9885e-01, 1.3203e-01, 8.9139e-01, 5.6505e-01,\n",
       "         2.4642e-01, 7.2054e-01, 4.6820e-01, 9.6395e-01, 3.6898e-02, 2.2145e-01,\n",
       "         7.4313e-01, 4.0338e-01, 6.8872e-01, 4.2958e-01, 3.5139e-01, 3.3349e-01,\n",
       "         1.3118e-01, 5.3955e-02, 8.5006e-01, 8.1072e-01, 6.0530e-01, 9.3056e-01,\n",
       "         9.3692e-02, 2.2491e-03, 5.7569e-02, 1.8067e-01, 7.4105e-01, 7.8619e-01,\n",
       "         2.6806e-01, 5.1054e-01, 7.7766e-01, 7.3445e-01, 7.3640e-01, 5.0540e-01,\n",
       "         3.0560e-01, 8.5233e-02, 5.8960e-02, 4.9929e-01, 1.0401e-01, 4.8851e-01,\n",
       "         8.2774e-01, 5.6883e-02, 2.9997e-01, 6.7915e-01, 3.1760e-01, 2.1033e-01,\n",
       "         7.9907e-01, 3.1216e-01, 1.4986e-01, 4.6182e-01, 2.2673e-01, 8.0697e-01,\n",
       "         1.9300e-01, 6.7192e-01, 3.9800e-01, 7.0701e-01, 4.2414e-01, 7.6621e-01,\n",
       "         9.1106e-01, 7.3888e-01, 7.6957e-01, 5.6581e-01, 7.3250e-01, 5.7118e-01,\n",
       "         5.3973e-01, 7.9142e-01, 5.8672e-01, 6.5867e-01, 2.6000e-01, 5.4438e-01,\n",
       "         2.6692e-01, 5.8059e-01, 7.2528e-02, 9.8426e-01, 2.1890e-01, 9.6886e-01,\n",
       "         9.4145e-01, 8.1056e-02, 8.4987e-02, 5.2037e-01, 3.0228e-01, 8.6734e-01,\n",
       "         6.9337e-01, 6.1015e-02, 6.3884e-01, 4.9873e-01, 5.3447e-01, 7.0581e-01,\n",
       "         8.9074e-01, 6.4489e-01, 2.6877e-01, 6.0473e-01, 1.3204e-01, 2.8230e-01,\n",
       "         1.2392e-01, 7.7119e-01, 1.9932e-01, 3.6001e-01, 9.9426e-02, 5.3195e-02,\n",
       "         5.5054e-01, 2.6722e-01, 7.8695e-01, 8.3168e-01, 4.1929e-01, 5.2201e-01,\n",
       "         4.4890e-01, 3.2164e-01, 6.5095e-01, 4.7817e-01, 4.6272e-01, 5.1702e-01,\n",
       "         8.9772e-01, 7.8682e-01, 5.3054e-01, 9.0772e-01, 9.7864e-01, 1.8933e-01,\n",
       "         1.3341e-01, 7.9063e-01, 3.9606e-01, 1.6758e-01, 5.8437e-01, 1.5098e-01,\n",
       "         5.0444e-01, 1.9120e-01, 1.5601e-01, 4.8158e-01, 8.6080e-01, 6.1614e-01,\n",
       "         6.8174e-01, 8.9946e-01, 7.8275e-01, 7.9147e-01, 1.1898e-01, 1.4901e-01,\n",
       "         2.3138e-02, 7.8451e-01, 3.4861e-01, 6.7978e-01, 9.0640e-01, 3.7007e-01,\n",
       "         5.2954e-01, 2.8268e-01, 3.4365e-01, 9.4665e-01, 4.7441e-01, 2.4299e-01,\n",
       "         8.2342e-01, 1.4420e-01, 7.9653e-01, 3.4270e-01, 1.9734e-01, 3.6753e-01,\n",
       "         7.5413e-01, 8.3698e-01, 3.5131e-01, 6.7998e-01, 3.9345e-01, 3.1370e-02,\n",
       "         6.1058e-01, 1.3925e-01, 9.7461e-01, 9.1933e-01, 8.8710e-01, 4.7307e-01,\n",
       "         2.6038e-01, 3.1230e-01, 9.1036e-01, 3.2535e-01, 8.7874e-01, 5.0527e-01,\n",
       "         3.9525e-01, 3.0565e-01, 7.8062e-01, 9.3017e-01, 7.4220e-01, 8.3421e-01,\n",
       "         3.0743e-01, 5.9793e-01, 7.5585e-02, 8.6163e-01, 3.2883e-01, 3.6336e-01,\n",
       "         9.4776e-01, 5.2430e-02, 5.5685e-01, 5.7082e-02, 2.7097e-01, 2.5836e-01,\n",
       "         8.1886e-01, 6.4866e-01, 7.0331e-01, 6.0729e-01, 3.4225e-01, 3.1031e-01,\n",
       "         3.9267e-01, 5.1047e-01, 8.0177e-01, 2.1973e-01, 7.7614e-01, 5.7678e-01,\n",
       "         9.2149e-01, 1.1927e-01, 4.9193e-01, 9.4519e-01, 3.0081e-01, 5.1345e-01,\n",
       "         9.9723e-01, 2.8787e-01, 8.2763e-01, 8.8867e-01, 5.8741e-01, 6.3169e-01,\n",
       "         2.2934e-01, 9.2987e-01, 6.0898e-01, 2.5502e-01, 1.4015e-01, 7.3548e-02,\n",
       "         9.9663e-01, 3.8005e-01, 1.8084e-01, 5.3301e-01]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model(data) # forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = (prediction - labels).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwane/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py:132: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  allow_unreachable=True)  # allow_unreachable flag\n"
     ]
    }
   ],
   "source": [
    "loss.backward() # backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim.step() #gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
